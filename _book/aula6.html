<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Regression inside out | Notes for Ecological Modelling</title>
  <meta name="description" content="This is based on Yihui Xie’s a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Regression inside out | Notes for Ecological Modelling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is based on Yihui Xie’s a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Regression inside out | Notes for Ecological Modelling" />
  
  <meta name="twitter:description" content="This is based on Yihui Xie’s a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Tiago A. Marques" />


<meta name="date" content="2023-11-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="handson.html"/>
<link rel="next" href="aula7.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="mainintro.html"><a href="mainintro.html"><i class="fa fa-check"></i><b>2</b> Preamble</a></li>
<li class="chapter" data-level="3" data-path="aknowledgments.html"><a href="aknowledgments.html"><i class="fa fa-check"></i><b>3</b> Aknowledgments</a></li>
<li class="chapter" data-level="4" data-path="usingRintro.html"><a href="usingRintro.html"><i class="fa fa-check"></i><b>4</b> Using R</a></li>
<li class="chapter" data-level="5" data-path="prelim.html"><a href="prelim.html"><i class="fa fa-check"></i><b>5</b> Preliminaries</a>
<ul>
<li class="chapter" data-level="5.1" data-path="prelim.html"><a href="prelim.html#lbtb"><i class="fa fa-check"></i><b>5.1</b> Learning by the book</a></li>
<li class="chapter" data-level="5.2" data-path="prelim.html"><a href="prelim.html#ftpt"><i class="fa fa-check"></i><b>5.2</b> Following the paper trail</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="about-regression.html"><a href="about-regression.html"><i class="fa fa-check"></i><b>6</b> About regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="about-regression.html"><a href="about-regression.html#what-is-a-regression"><i class="fa fa-check"></i><b>6.1</b> What is a regression?</a></li>
<li class="chapter" data-level="6.2" data-path="about-regression.html"><a href="about-regression.html#the-general-linear-model"><i class="fa fa-check"></i><b>6.2</b> The general linear model</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="handson.html"><a href="handson.html"><i class="fa fa-check"></i><b>7</b> Hands On Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="handson.html"><a href="handson.html#the-assumptions-are-on-the-residuals-not-the-data"><i class="fa fa-check"></i><b>7.1</b> The assumptions are on the residuals, not the data</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="aula6.html"><a href="aula6.html"><i class="fa fa-check"></i><b>8</b> Regression inside out</a>
<ul>
<li class="chapter" data-level="8.1" data-path="aula6.html"><a href="aula6.html#implementing-a-regression"><i class="fa fa-check"></i><b>8.1</b> Implementing a regression</a></li>
<li class="chapter" data-level="8.2" data-path="aula6.html"><a href="aula6.html#simulating-regression-data"><i class="fa fa-check"></i><b>8.2</b> Simulating regression data</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="aula6.html"><a href="aula6.html#what-is-the-effect-of-increasing-the-error-a-simulation-experiment"><i class="fa fa-check"></i><b>8.2.1</b> What is the effect of increasing the error: a simulation experiment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="aula7.html"><a href="aula7.html"><i class="fa fa-check"></i><b>9</b> Two tasks to further understand regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="aula7.html"><a href="aula7.html#task-1"><i class="fa fa-check"></i><b>9.1</b> Task 1</a></li>
<li class="chapter" data-level="9.2" data-path="aula7.html"><a href="aula7.html#task-2"><i class="fa fa-check"></i><b>9.2</b> Task 2</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="aula8.html"><a href="aula8.html"><i class="fa fa-check"></i><b>10</b> t-tests and ANOVAs are just linear models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="aula8.html"><a href="aula8.html#a-one-sample-t-test-is-the-simplest-possible-linear-model"><i class="fa fa-check"></i><b>10.1</b> A one sample t-test is the simplest possible linear model</a></li>
<li class="chapter" data-level="10.2" data-path="aula8.html"><a href="aula8.html#the-t-test"><i class="fa fa-check"></i><b>10.2</b> The t-test</a></li>
<li class="chapter" data-level="10.3" data-path="aula8.html"><a href="aula8.html#anova"><i class="fa fa-check"></i><b>10.3</b> ANOVA</a></li>
<li class="chapter" data-level="10.4" data-path="aula8.html"><a href="aula8.html#a-two-way-anova-and-beyhond-ex-task-do-it-yourself"><i class="fa fa-check"></i><b>10.4</b> A two way ANOVA, and beyhond (ex Task: do it yourself!)</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="aula9.html"><a href="aula9.html"><i class="fa fa-check"></i><b>11</b> Class 9: 21 10 2020 - ANCOVA is (also) just a linear model</a>
<ul>
<li class="chapter" data-level="11.1" data-path="aula9.html"><a href="aula9.html#common-slope-different-intercepts-per-treatment"><i class="fa fa-check"></i><b>11.1</b> Common slope, different intercepts per treatment</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="aula10.html"><a href="aula10.html"><i class="fa fa-check"></i><b>12</b> Class 10: 27 10 2020</a>
<ul>
<li class="chapter" data-level="12.1" data-path="aula10.html"><a href="aula10.html#same-story-another-spin"><i class="fa fa-check"></i><b>12.1</b> Same story, another spin</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="aula11.html"><a href="aula11.html"><i class="fa fa-check"></i><b>13</b> Class 11: 03 11 2020 ANCOVA with different slopes: interactions</a>
<ul>
<li class="chapter" data-level="13.1" data-path="aula11.html"><a href="aula11.html#about-interactions"><i class="fa fa-check"></i><b>13.1</b> About interactions</a></li>
<li class="chapter" data-level="13.2" data-path="aula11.html"><a href="aula11.html#task-1-implementing-the-ancova-with-different-slopes"><i class="fa fa-check"></i><b>13.2</b> Task 1 Implementing the ANCOVA with different slopes</a></li>
<li class="chapter" data-level="13.3" data-path="aula11.html"><a href="aula11.html#task-2-modeling-a-data-set"><i class="fa fa-check"></i><b>13.3</b> Task 2 Modeling a data set</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="aula13.html"><a href="aula13.html"><i class="fa fa-check"></i><b>14</b> Class 12: 04 11 2020 Interactions between continous covariates</a>
<ul>
<li class="chapter" data-level="14.1" data-path="aula13.html"><a href="aula13.html#larger-order-interactions"><i class="fa fa-check"></i><b>14.1</b> Larger order interactions</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="conclusion-on-linear-regression.html"><a href="conclusion-on-linear-regression.html"><i class="fa fa-check"></i><b>15</b> Conclusion on linear regression</a>
<ul>
<li class="chapter" data-level="15.1" data-path="conclusion-on-linear-regression.html"><a href="conclusion-on-linear-regression.html#conclusion"><i class="fa fa-check"></i><b>15.1</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="aula12.html"><a href="aula12.html"><i class="fa fa-check"></i><b>16</b> Class 13: 10 11 2020 Maximum likelihood and all that</a>
<ul>
<li class="chapter" data-level="16.1" data-path="aula12.html"><a href="aula12.html#maximizing-a-likelihood-algebraically"><i class="fa fa-check"></i><b>16.1</b> Maximizing a likelihood algebraically</a></li>
<li class="chapter" data-level="16.2" data-path="aula12.html"><a href="aula12.html#numerically-maximizing-a-likelihood"><i class="fa fa-check"></i><b>16.2</b> Numerically Maximizing a likelihood</a></li>
<li class="chapter" data-level="16.3" data-path="aula12.html"><a href="aula12.html#the-case-of-a-gaussian"><i class="fa fa-check"></i><b>16.3</b> The case of a Gaussian</a></li>
<li class="chapter" data-level="16.4" data-path="aula12.html"><a href="aula12.html#the-case-of-a-linear-model"><i class="fa fa-check"></i><b>16.4</b> The case of a linear model</a></li>
<li class="chapter" data-level="16.5" data-path="aula12.html"><a href="aula12.html#the-really-interesting-case"><i class="fa fa-check"></i><b>16.5</b> The really interesting case</a></li>
<li class="chapter" data-level="16.6" data-path="aula12.html"><a href="aula12.html#likelihood-above-and-beyond"><i class="fa fa-check"></i><b>16.6</b> Likelihood, above and beyond</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="aula14.html"><a href="aula14.html"><i class="fa fa-check"></i><b>17</b> Class 14: 11 11 2020 GLMs</a>
<ul>
<li class="chapter" data-level="17.1" data-path="aula14.html"><a href="aula14.html#what-are-glms"><i class="fa fa-check"></i><b>17.1</b> What are GLMs</a></li>
<li class="chapter" data-level="17.2" data-path="aula14.html"><a href="aula14.html#the-link-function"><i class="fa fa-check"></i><b>17.2</b> The link function</a></li>
<li class="chapter" data-level="17.3" data-path="aula14.html"><a href="aula14.html#most-useful-glm-families"><i class="fa fa-check"></i><b>17.3</b> Most useful GLM Families</a></li>
<li class="chapter" data-level="17.4" data-path="aula14.html"><a href="aula14.html#an-example-analysis"><i class="fa fa-check"></i><b>17.4</b> An example analysis</a></li>
<li class="chapter" data-level="17.5" data-path="aula14.html"><a href="aula14.html#an-example-of-a-glm-as-a-detail-within-a-conceptualization-framework"><i class="fa fa-check"></i><b>17.5</b> An example of a GLM as a detail within a conceptualization framework</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="aula15.html"><a href="aula15.html"><i class="fa fa-check"></i><b>18</b> Class 15: 17 11 2020</a>
<ul>
<li class="chapter" data-level="18.1" data-path="aula15.html"><a href="aula15.html#example-2"><i class="fa fa-check"></i><b>18.1</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="aula16.html"><a href="aula16.html"><i class="fa fa-check"></i><b>19</b> Class 16: 18 11 2020</a>
<ul>
<li class="chapter" data-level="19.1" data-path="aula16.html"><a href="aula16.html#a-logistic-regression-example"><i class="fa fa-check"></i><b>19.1</b> A logistic regression example</a></li>
<li class="chapter" data-level="19.2" data-path="aula16.html"><a href="aula16.html#titanic-example"><i class="fa fa-check"></i><b>19.2</b> Titanic example</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="aula16.html"><a href="aula16.html#análise-exploratoria-de-dados"><i class="fa fa-check"></i><b>19.2.1</b> Análise Exploratoria de Dados</a></li>
<li class="chapter" data-level="19.2.2" data-path="aula16.html"><a href="aula16.html#modelação"><i class="fa fa-check"></i><b>19.2.2</b> Modelação</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="aula16.html"><a href="aula16.html#about-multicollinearity"><i class="fa fa-check"></i><b>19.3</b> About multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="aula17.html"><a href="aula17.html"><i class="fa fa-check"></i><b>20</b> Random effects and mixed Models</a></li>
<li class="chapter" data-level="21" data-path="aula18.html"><a href="aula18.html"><i class="fa fa-check"></i><b>21</b> Class 18: 25 11 2020</a>
<ul>
<li class="chapter" data-level="21.1" data-path="aula18.html"><a href="aula18.html#presence-of-bats"><i class="fa fa-check"></i><b>21.1</b> Presence of bats</a></li>
<li class="chapter" data-level="21.2" data-path="aula18.html"><a href="aula18.html#sponges"><i class="fa fa-check"></i><b>21.2</b> Sponges</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="aula18.html"><a href="aula18.html#reading-data-in"><i class="fa fa-check"></i><b>21.2.1</b> Reading data in</a></li>
<li class="chapter" data-level="21.2.2" data-path="aula18.html"><a href="aula18.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>21.2.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="21.2.3" data-path="aula18.html"><a href="aula18.html#modelling"><i class="fa fa-check"></i><b>21.2.3</b> Modelling</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="aula18.html"><a href="aula18.html#extra-glm-stuff"><i class="fa fa-check"></i><b>21.3</b> Extra GLM stuff</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="aula19.html"><a href="aula19.html"><i class="fa fa-check"></i><b>22</b> Class 19: 02 12 2020</a></li>
<li class="chapter" data-level="23" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>23</b> Final Words</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes for Ecological Modelling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="aula6" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Regression inside out<a href="aula6.html#aula6" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this section we will look at regression models from different angles. Hopefully, by the end of this section, you will have mastered the linear model and will be able to recognize that several statistical procedures with famous names (like t-tests or ANOVA) are just special cases of the linear model.</p>
<div id="implementing-a-regression" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Implementing a regression<a href="aula6.html#implementing-a-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider a dataset where we have the weight and lengths of lizards, and we are interested in modelling the weight as a function of the length of the available individuals. This will provide us an excuse to look at the different aspects of a linear model and the corresponding output.</p>
<p>The dataset is available as a text file: “lagartos.txt” . We begin by reading the data in “lagartos.txt”, exploring the data and then fitting a simple regression, a linear model, to the data. Just as a detail regarding wording, which reflects what the procedure does, we fit models to data, we do not fit data to models!</p>
<p>We begin by reading the data in</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="aula6.html#cb1-1" tabindex="-1"></a><span class="co">#folder&lt;-&quot;../Aula6 13 10 2020/&quot;</span></span>
<span id="cb1-2"><a href="aula6.html#cb1-2" tabindex="-1"></a>folder<span class="ot">&lt;-</span><span class="st">&quot;extfiles/&quot;</span></span>
<span id="cb1-3"><a href="aula6.html#cb1-3" tabindex="-1"></a>lagartos <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file=</span><span class="fu">paste0</span>(folder,<span class="st">&quot;lagartos.txt&quot;</span>), <span class="at">sep=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb1-4"><a href="aula6.html#cb1-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(lagartos)</span></code></pre></div>
<p>We can see that we have observations over 97 individuals, for which we have recorded both lengths and weights. We can plot the data, being careful to have the response variable, the weights, on the y-axis, and the explanatory variable, the lengths, on the x-axis.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="aula6.html#cb2-1" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(peso<span class="sc">~</span>comp))</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.2-1.png" width="672" /></p>
<p>(tip begins here)</p>
<p>Tip: A common “rookie” mistake is to confuse the defaul R ploting syntax, and mix the two. Note that <code>plot(y~x)</code> is equivalent to <code>plot(x,y)</code> but different from <code>plot(x~y)</code>. The latter is not what you want, ´~´ should be read as “as a function of” and so you must have the response on the left side of the tilde, but by default the first argument to the function plot is the <span class="math inline">\(x\)</span>, usually by convention the explanatory variable. The next figure illustrates the differences, where I don’t set the axis labels so that the consequences are transparent</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="aula6.html#cb3-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>),<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>))</span>
<span id="cb3-2"><a href="aula6.html#cb3-2" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(peso<span class="sc">~</span>comp))</span>
<span id="cb3-3"><a href="aula6.html#cb3-3" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(peso,comp))</span>
<span id="cb3-4"><a href="aula6.html#cb3-4" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(comp<span class="sc">~</span>peso))</span>
<span id="cb3-5"><a href="aula6.html#cb3-5" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(comp,peso))</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>(tip ends here)</p>
<p>A linear model seems adequate to represent the weights as a function of the lengths. This is not surprising, especially since we simulated the data to be so. We fit a linear model to the data</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="aula6.html#cb4-1" tabindex="-1"></a>lmlag <span class="ot">&lt;-</span> <span class="fu">lm</span>(peso<span class="sc">~</span>comp,<span class="at">data=</span>lagartos)</span>
<span id="cb4-2"><a href="aula6.html#cb4-2" tabindex="-1"></a><span class="fu">summary</span>(lmlag)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = peso ~ comp, data = lagartos)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.5199 -1.6961  0.3495  1.7490  4.7127 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 11.72234    0.72299   16.21   &lt;2e-16 ***
## comp         1.20233    0.05402   22.26   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.415 on 95 degrees of freedom
## Multiple R-squared:  0.8391, Adjusted R-squared:  0.8374 
## F-statistic: 495.3 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>(tip begins here)</p>
<p>Remember that a linear model is just a special generalized linear model (GLM):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="aula6.html#cb6-1" tabindex="-1"></a>glmlag <span class="ot">&lt;-</span> <span class="fu">glm</span>(peso<span class="sc">~</span>comp,<span class="at">data=</span>lagartos,<span class="at">family=</span><span class="fu">gaussian</span>(<span class="at">link=</span><span class="st">&quot;identity&quot;</span>))</span>
<span id="cb6-2"><a href="aula6.html#cb6-2" tabindex="-1"></a><span class="fu">summary</span>(glmlag)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = peso ~ comp, family = gaussian(link = &quot;identity&quot;), 
##     data = lagartos)
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 11.72234    0.72299   16.21   &lt;2e-16 ***
## comp         1.20233    0.05402   22.26   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 5.830492)
## 
##     Null deviance: 3441.8  on 96  degrees of freedom
## Residual deviance:  553.9  on 95  degrees of freedom
## AIC: 450.27
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>as we can see the output looks a bit different (after all, <code>lm</code> and <code>glm</code> are different functions!), but the results are exactly the same. This does not prove it, but it illustrates by example that a linear model is just a GLM with a Gaussian response and an <code>identity</code> link function.</p>
<p>Lets use the results from <code>lm</code>, while noting that everything else would be the same.</p>
<p>(tip ends here)</p>
<p>The estimated regression line is</p>
<p><span class="math display">\[weight= a+b \times length\]</span>
or in this case, with the estimated parameter values,</p>
<p><span class="math display">\[ peso =11.72 +1.2 \times comp \]</span></p>
<p>and the estimated R-squared is 0.84. The standard error associated with the model is estimated to be 2.4146. Below we explain in detail what each of these values correspond to, but for now bear in mind that the estimated standard error corresponds to the standard deviation of the residuals of the model, that is, the difference between the observations and the predicted values given the model. The observation we have already as data, those are the <code>peso</code>. We can obtain the predicted <code>peso</code> for each observation with the function <code>predict</code>, but here we do it manually so that we see that the errors are just the observations minus the predictions.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="aula6.html#cb8-1" tabindex="-1"></a><span class="co">#get estimated values</span></span>
<span id="cb8-2"><a href="aula6.html#cb8-2" tabindex="-1"></a>estimated<span class="ot">&lt;-</span><span class="fu">with</span>(lagartos,<span class="fu">summary</span>(lmlag)<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">+</span><span class="fu">summary</span>(lmlag)<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>comp)</span>
<span id="cb8-3"><a href="aula6.html#cb8-3" tabindex="-1"></a><span class="co"># note this would be the same as</span></span>
<span id="cb8-4"><a href="aula6.html#cb8-4" tabindex="-1"></a><span class="co"># estimated&lt;-predict(lmlag)</span></span></code></pre></div>
<p>Now we can compute the residuals and their corresponding standard error</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="aula6.html#cb9-1" tabindex="-1"></a><span class="co">#get residuals</span></span>
<span id="cb9-2"><a href="aula6.html#cb9-2" tabindex="-1"></a><span class="co">#erros = observações - valores previstos</span></span>
<span id="cb9-3"><a href="aula6.html#cb9-3" tabindex="-1"></a><span class="co"># e= y- (a+bx)</span></span>
<span id="cb9-4"><a href="aula6.html#cb9-4" tabindex="-1"></a><span class="co"># y= (a+bx) + e</span></span>
<span id="cb9-5"><a href="aula6.html#cb9-5" tabindex="-1"></a>resid<span class="ot">&lt;-</span>lagartos<span class="sc">$</span>peso<span class="sc">-</span>estimated</span>
<span id="cb9-6"><a href="aula6.html#cb9-6" tabindex="-1"></a><span class="fu">sd</span>(resid)</span></code></pre></div>
<pre><code>## [1] 2.402032</code></pre>
<p>Note as <code>predict</code>, we could use just the function <code>residuals</code> with the model object as argument to get us the residuals in a single line of code.</p>
<p>The reason the above standard error is not exactly the same as in the model output above has to do with the degrees of freedom, a concept that is hard to explain in this applied context, but relates to the number of available independent bits of information available. So trust me when I say that we loose a degree of freedom for each parameter estimated in a model. The exact value of the standard deviation as estimated in the model must account for that loss of one extra degree of freedom (associated with estimating the slope of the line), and so the standard formula of the <code>sd</code> needs to be adjusted for the lost degree of freedom, like this:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="aula6.html#cb11-1" tabindex="-1"></a><span class="co">#Residual Standard error (Like Standard Deviation)</span></span>
<span id="cb11-2"><a href="aula6.html#cb11-2" tabindex="-1"></a><span class="co">#the right way</span></span>
<span id="cb11-3"><a href="aula6.html#cb11-3" tabindex="-1"></a><span class="co">#Subtract one to ignore intercept</span></span>
<span id="cb11-4"><a href="aula6.html#cb11-4" tabindex="-1"></a>k<span class="ot">=</span><span class="fu">length</span>(lmlag<span class="sc">$</span>coefficients)<span class="sc">-</span><span class="dv">1</span> </span>
<span id="cb11-5"><a href="aula6.html#cb11-5" tabindex="-1"></a><span class="co">#get the error sum of squares</span></span>
<span id="cb11-6"><a href="aula6.html#cb11-6" tabindex="-1"></a>SSE<span class="ot">=</span><span class="fu">sum</span>(lmlag<span class="sc">$</span>residuals<span class="sc">**</span><span class="dv">2</span>)</span>
<span id="cb11-7"><a href="aula6.html#cb11-7" tabindex="-1"></a><span class="co">#Residual Standard Error</span></span>
<span id="cb11-8"><a href="aula6.html#cb11-8" tabindex="-1"></a><span class="fu">sqrt</span>(SSE<span class="sc">/</span>(n<span class="sc">-</span>(<span class="dv">1</span><span class="sc">+</span>k))) </span></code></pre></div>
<pre><code>## [1] 2.414641</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="aula6.html#cb13-1" tabindex="-1"></a><span class="co">#equivalently</span></span>
<span id="cb13-2"><a href="aula6.html#cb13-2" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">var</span>(resid)<span class="sc">*</span>(n<span class="dv">-1</span>)<span class="sc">/</span>(n<span class="dv">-2</span>))</span></code></pre></div>
<pre><code>## [1] 2.414641</code></pre>
<p>Now we get the exact same value as above: 2.415.</p>
<p>The <code>summary</code> of the model above is very useful, but nothing like adding the estimated model to the plot with the data. We can easily add the line to the plot with function <code>abline</code> </p>
<p>(tip begins here)</p>
<p>The <code>ab</code> in <code>abline</code> corresponds simply to the <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> in <span class="math inline">\(y=a+bx\)</span>, but the function <code>abline</code> is “smart” enough to take other arguments than just an intercept and slope a slope as arguments. It can take</p>
<ul>
<li>an object of class <code>lm</code> and extract the corresponding <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> for plotting</li>
<li>argument <code>v</code> to add vertical line(s) to an existing plot (e.g. <code>v=20</code> would add a vertical line at <code>x=20</code> to an existing plot)</li>
<li>argument <code>h</code> to add horizontal line(s) to an existing plot (e.g. <code>h=10</code> would add a horizontal line at <code>y=10</code> to an existing plot)</li>
</ul>
<p>(tip ends here)</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="aula6.html#cb15-1" tabindex="-1"></a><span class="co">#with(lagartos,plot(peso~comp))</span></span>
<span id="cb15-2"><a href="aula6.html#cb15-2" tabindex="-1"></a><span class="fu">plot</span>(peso<span class="sc">~</span>comp,<span class="at">data=</span>lagartos)</span>
<span id="cb15-3"><a href="aula6.html#cb15-3" tabindex="-1"></a><span class="co">#these next 3 lines are equivalent</span></span>
<span id="cb15-4"><a href="aula6.html#cb15-4" tabindex="-1"></a><span class="fu">abline</span>(lmlag,<span class="at">col=</span><span class="st">&quot;orange&quot;</span>)</span>
<span id="cb15-5"><a href="aula6.html#cb15-5" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="fl">11.72234</span>,<span class="at">b=</span><span class="fl">1.20233</span>,<span class="at">col=</span><span class="st">&quot;pink&quot;</span>)</span>
<span id="cb15-6"><a href="aula6.html#cb15-6" tabindex="-1"></a><span class="co"># y = a + bx</span></span>
<span id="cb15-7"><a href="aula6.html#cb15-7" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="fu">summary</span>(lmlag)<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">1</span>],<span class="at">b=</span><span class="fu">summary</span>(lmlag)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">1</span>],<span class="at">col=</span><span class="st">&quot;brown&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.9-1.png" width="672" /></p>
<p>Note the last line works because the parameter estimates are hold in a component of the <code>summary</code> of the fitted model called <code>coefficients</code></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="aula6.html#cb16-1" tabindex="-1"></a><span class="fu">summary</span>(lmlag)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##              Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept) 11.722343 0.72299153 16.21367 4.135172e-29
## comp         1.202333 0.05402397 22.25555 1.839784e-39</code></pre>
<p>Additionally, we can also add the residuals in the plot (we use the very handy function <code>segments</code>, that adds segments to existing plots, to do so)</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="aula6.html#cb18-1" tabindex="-1"></a><span class="co"># get estimated/predicted values with function residuals</span></span>
<span id="cb18-2"><a href="aula6.html#cb18-2" tabindex="-1"></a>estimated2<span class="ot">&lt;-</span><span class="fu">predict</span>(lmlag)</span>
<span id="cb18-3"><a href="aula6.html#cb18-3" tabindex="-1"></a><span class="co">#plot the data</span></span>
<span id="cb18-4"><a href="aula6.html#cb18-4" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(peso<span class="sc">~</span>comp,<span class="at">pch=</span><span class="dv">21</span>,<span class="at">bg=</span><span class="st">&quot;brown&quot;</span>,<span class="at">col=</span><span class="st">&quot;green&quot;</span>))</span>
<span id="cb18-5"><a href="aula6.html#cb18-5" tabindex="-1"></a><span class="fu">abline</span>(lmlag,<span class="at">col=</span><span class="dv">3</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb18-6"><a href="aula6.html#cb18-6" tabindex="-1"></a><span class="co">#add residuals</span></span>
<span id="cb18-7"><a href="aula6.html#cb18-7" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">segments</span>(<span class="at">x0 =</span> comp,<span class="at">y0 =</span> peso, <span class="at">x1=</span> comp, <span class="at">y1=</span>estimated,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.11-1.png" width="672" /></p>
<p>The regression line corresponds to the line that minimizes the sum of the red distances in the plot above. That is also why it is called a minimum squares line in the special case of a Gaussian model (in PT, é a reta dos mínimos quadrados).</p>
<p>The residuals should, if the model is reasonable - and here that should be the case, as we are using simulated data - be well approximated by a Gaussian distribution. Note we can get the values of the residuals by the difference between the observations and the estimated values, as we did above, or just use the function <code>resid</code> over a fitted model, for simplicity. We can look at an histogram of the residuals below</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="aula6.html#cb19-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb19-2"><a href="aula6.html#cb19-2" tabindex="-1"></a><span class="fu">hist</span>(resid,<span class="at">main=</span><span class="st">&quot;Residuals by hand&quot;</span>,<span class="at">freq=</span><span class="cn">FALSE</span>)</span>
<span id="cb19-3"><a href="aula6.html#cb19-3" tabindex="-1"></a><span class="co">#adding the theorethical density of a Gaussian with mean 0 and the</span></span>
<span id="cb19-4"><a href="aula6.html#cb19-4" tabindex="-1"></a><span class="co">#correct standard error</span></span>
<span id="cb19-5"><a href="aula6.html#cb19-5" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">8</span>,<span class="at">by=</span><span class="fl">0.1</span>),<span class="fu">dnorm</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">8</span>,<span class="at">by=</span><span class="fl">0.1</span>),<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd=</span><span class="fu">summary</span>(lmlag)<span class="sc">$</span>sigma))</span>
<span id="cb19-6"><a href="aula6.html#cb19-6" tabindex="-1"></a></span>
<span id="cb19-7"><a href="aula6.html#cb19-7" tabindex="-1"></a>resid2<span class="ot">&lt;-</span><span class="fu">residuals</span>(lmlag)</span>
<span id="cb19-8"><a href="aula6.html#cb19-8" tabindex="-1"></a><span class="fu">hist</span>(resid2,<span class="at">main=</span><span class="st">&quot;Residuals by function residuals&quot;</span>)</span>
<span id="cb19-9"><a href="aula6.html#cb19-9" tabindex="-1"></a></span>
<span id="cb19-10"><a href="aula6.html#cb19-10" tabindex="-1"></a><span class="co">#correct standard error</span></span>
<span id="cb19-11"><a href="aula6.html#cb19-11" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">8</span>,<span class="at">by=</span><span class="fl">0.1</span>),<span class="fu">dnorm</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="dv">8</span>,<span class="at">by=</span><span class="fl">0.1</span>),<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd=</span><span class="fu">summary</span>(lmlag)<span class="sc">$</span>sigma))</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.12-1.png" width="672" /></p>
<p>It is often said that the <span class="math inline">\(R^2\)</span> represents the amount of variation in the response that the regression explains, and we are now in a position to illustrate exactly why that is the case. If you assume that all the variability in the response data, the <span class="math inline">\(y_i\)</span>, as the difference between the data points and a common mean</p>
<p><span class="math display">\[\sum_{i=1}^n (y_i- \bar y)^2\]</span>
in an image, the sum of the square of these quantities</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="aula6.html#cb20-1" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb20-2"><a href="aula6.html#cb20-2" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(peso<span class="sc">~</span>comp))</span>
<span id="cb20-3"><a href="aula6.html#cb20-3" tabindex="-1"></a><span class="fu">abline</span>(lmlag,<span class="at">col=</span><span class="dv">3</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb20-4"><a href="aula6.html#cb20-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">mean</span>(lagartos<span class="sc">$</span>peso))</span>
<span id="cb20-5"><a href="aula6.html#cb20-5" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">segments</span>(<span class="at">x0 =</span> comp,<span class="at">y0 =</span> peso, <span class="at">x1=</span> comp, <span class="at">y1=</span><span class="fu">mean</span>(peso),<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="dv">2</span>))</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.14-1.png" width="672" /></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="aula6.html#cb21-1" tabindex="-1"></a>all.var<span class="ot">&lt;-</span><span class="fu">sum</span>((lagartos<span class="sc">$</span>peso<span class="sc">-</span><span class="fu">mean</span>(lagartos<span class="sc">$</span>peso))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb21-2"><a href="aula6.html#cb21-2" tabindex="-1"></a>all.var</span></code></pre></div>
<pre><code>## [1] 3441.795</code></pre>
<p>and the variability that is not explained is the one that remains in the errors - for which the corresponding plot illustrating the concept geometrically was shown above, that is</p>
<p><span class="math display">\[\sum_{i=1}^n (y_i- \hat y_i)^2\]</span></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="aula6.html#cb23-1" tabindex="-1"></a>error.var<span class="ot">&lt;-</span><span class="fu">sum</span>((lagartos<span class="sc">$</span>peso<span class="sc">-</span>estimated)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb23-2"><a href="aula6.html#cb23-2" tabindex="-1"></a>error.var</span></code></pre></div>
<pre><code>## [1] 553.8968</code></pre>
<p>then the ratio of those two quantities is what is not explained by the regression model, and therefore, 1 minus that is what explained by the regression model:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="aula6.html#cb25-1" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span>error.var<span class="sc">/</span>all.var</span></code></pre></div>
<pre><code>## [1] 0.8390675</code></pre>
<p>And that… as noted above… is the <span class="math inline">\(R^2\)</span>=0.8391. This comes from the fact that all of the variability in the data (the <span class="math inline">\(y\)</span>, the response, here the <code>peso</code>) can be decomposed into the variability explained by the model, and the unexplained variability, that of the errors. In a formula</p>
<p><span class="math display">\[SS_{TOTAL}=SS_{REGRESSÃO}+SS_{ERRO}\]</span></p>
<p>Note naturally we could also represent in an image what is explained by the regression model, which is</p>
<p><span class="math display">\[\sum_{i=1}^n (\hat y_i- \bar y)^2\]</span></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="aula6.html#cb27-1" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb27-2"><a href="aula6.html#cb27-2" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">plot</span>(peso<span class="sc">~</span>comp))</span>
<span id="cb27-3"><a href="aula6.html#cb27-3" tabindex="-1"></a><span class="fu">abline</span>(lmlag,<span class="at">col=</span><span class="dv">3</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb27-4"><a href="aula6.html#cb27-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">mean</span>(lagartos<span class="sc">$</span>peso))</span>
<span id="cb27-5"><a href="aula6.html#cb27-5" tabindex="-1"></a><span class="fu">with</span>(lagartos,<span class="fu">segments</span>(<span class="at">x0 =</span> comp,<span class="at">y0 =</span> estimated, <span class="at">x1=</span> comp, <span class="at">y1=</span><span class="fu">mean</span>(peso),<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="dv">2</span>))</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.18-1.png" width="672" /></p>
<p>and that naturally is obtained as</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="aula6.html#cb28-1" tabindex="-1"></a>reg.var<span class="ot">&lt;-</span><span class="fu">sum</span>((<span class="fu">mean</span>(lagartos<span class="sc">$</span>peso)<span class="sc">-</span>estimated)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-2"><a href="aula6.html#cb28-2" tabindex="-1"></a>reg.var</span></code></pre></div>
<pre><code>## [1] 2887.898</code></pre>
<p>and hence the total variability is given by the sum <span class="math inline">\(SS_{REGRESSÃO}+SS_{ERRO}\)</span></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="aula6.html#cb30-1" tabindex="-1"></a>reg.var<span class="sc">+</span>error.var</span></code></pre></div>
<pre><code>## [1] 3441.795</code></pre>
<p>which we had already established to be the total variability in the response</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="aula6.html#cb32-1" tabindex="-1"></a>all.var</span></code></pre></div>
<pre><code>## [1] 3441.795</code></pre>
<p>So, remember that</p>
<p><span class="math display">\[SS_{TOTAL}=SS_{REGRESSÃO}+SS_{ERRO}\]</span></p>
<p>This is something that is often stated without a clear explanation of the reason why that holds. While here I show it by example, it could be easily demonstrated algebraically if one wanted that</p>
<p><span class="math display">\[\sum_{i=1}^n (y_i- \bar y)^2=\sum_{i=1}^n (\hat y_i- \bar y)^2 + \sum_{i=1}^n (y_i- \hat y_i)^2\]</span></p>
<p>If you want to see that that, this 28 minute video shows you the proof: <a href="https://www.youtube.com/watch?v=aQ32qTjqqJM" class="uri">https://www.youtube.com/watch?v=aQ32qTjqqJM</a></p>
<p>I think it could take just 5 minutes ;) but many thanks to Dmitry Leiderman for having it out there! He does it in the context of ANOVA, but ANOVA is just a special case of regression, were you have a continuous response and a single categorical explanatory variable. Therefore, have fun!</p>
</div>
<div id="simulating-regression-data" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Simulating regression data<a href="aula6.html#simulating-regression-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Considering the above example, it should be possible for you to simulate similar data to that we had for the lizards, data assuming that the true relation between the weight and length of a lizard was given by</p>
<p><span class="math display">\[ peso = 12 + 1.2 * comp \]</span></p>
<p>Note that this is a luxury we never have as researchers dealing with real data, knowing what truth is. But creating data from know truth scenarios via simulation can be invaluanble, as it allows us to explore the preformance of methods wehn we know what we should expect from them.</p>
<p>Here we consider that the usual length of a lizard can be between 5 and 20 cm, and the standard error is 4. As in the data we will have 97 lizards.</p>
<p>Then you were told to create the lengths:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="aula6.html#cb34-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">121</span>)</span>
<span id="cb34-2"><a href="aula6.html#cb34-2" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">97</span></span>
<span id="cb34-3"><a href="aula6.html#cb34-3" tabindex="-1"></a><span class="co">#lengths</span></span>
<span id="cb34-4"><a href="aula6.html#cb34-4" tabindex="-1"></a>xs<span class="ot">=</span><span class="fu">runif</span>(n,<span class="dv">5</span>,<span class="dv">20</span>)</span>
<span id="cb34-5"><a href="aula6.html#cb34-5" tabindex="-1"></a><span class="fu">hist</span>(xs,<span class="at">main=</span><span class="st">&quot;Lenths (cm)&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.21-1.png" width="672" /></p>
<p>and then to create weights of lizards</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="aula6.html#cb35-1" tabindex="-1"></a>a<span class="ot">=</span><span class="dv">12</span></span>
<span id="cb35-2"><a href="aula6.html#cb35-2" tabindex="-1"></a>b<span class="ot">=</span><span class="fl">1.2</span></span>
<span id="cb35-3"><a href="aula6.html#cb35-3" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs</span></code></pre></div>
<p>If we plot the data, all points are in a single line. Why? Because there is no randomness. Given the length of a lizard, we know the weight for sure.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="aula6.html#cb36-1" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.23-1.png" width="672" /></p>
<p>This means that if you try to run a model, it gives you a warning that the model might be unreliable</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="aula6.html#cb37-1" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(ys<span class="sc">~</span>xs))</span></code></pre></div>
<pre><code>## Warning in summary.lm(lm(ys ~ xs)): essentially perfect fit: summary may be
## unreliable</code></pre>
<pre><code>## 
## Call:
## lm(formula = ys ~ xs)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -5.595e-15 -2.460e-15 -1.878e-15 -1.422e-15  1.873e-13 
## 
## Coefficients:
##              Estimate Std. Error   t value Pr(&gt;|t|)    
## (Intercept) 1.200e+01  6.050e-15 1.983e+15   &lt;2e-16 ***
## xs          1.200e+00  4.611e-16 2.603e+15   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.934e-14 on 95 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 6.773e+30 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>reflecting that unlike what the model assumes, there would be no stochasticity in the data.</p>
<p>(tip begins here)</p>
<p>The data stochasticity, or variability, might be induced by process error, i.e. the model might not be perfect, hence not being deterministic as is always the case in nature, but also induced by observation error, e.g. because there is a random error in the measurement of the weights. In practice with a linear model we do not try to separate the two sources of errors, but in more advanced models that might be of interest in itself.</p>
<p>(tip ends here)</p>
<p>Therefore, we make the data realistic, and adhering to the model, by adding some variability to the data, in particular we assume the variability can be represented by Gaussian errors with mean zero and standard deviation of 4 units. Then we plot the data:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="aula6.html#cb40-1" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">4</span>)</span>
<span id="cb40-2"><a href="aula6.html#cb40-2" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.25-1.png" width="672" /></p>
<p>we can now fit a linear model to the data, whic we call <code>lmSimL</code> and explore the results</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="aula6.html#cb41-1" tabindex="-1"></a>SimL<span class="ot">&lt;-</span><span class="fu">data.frame</span>(ys,xs)</span>
<span id="cb41-2"><a href="aula6.html#cb41-2" tabindex="-1"></a>lmSimL<span class="ot">&lt;-</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs,<span class="at">data=</span>SimL)</span>
<span id="cb41-3"><a href="aula6.html#cb41-3" tabindex="-1"></a><span class="fu">summary</span>(lmSimL)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ys ~ xs, data = SimL)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.2024 -2.0587 -0.0304  2.2903  9.6963 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 10.47408    1.05716   9.908  2.6e-16 ***
## xs           1.38463    0.08057  17.186  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.379 on 95 degrees of freedom
## Multiple R-squared:  0.7566, Adjusted R-squared:  0.7541 
## F-statistic: 295.4 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We can extract from the model the relevant estimated quantities:</p>
<ul>
<li>the intercept is estimated to be 10.4740833 (using <code>coef(lmSimL)[1]</code>),</li>
<li>the slope is estimated to be 1.3846293 (using <code>coef(lmSimL)[2]</code>),</li>
<li>the residual error to be 3.3787165 (using <code>summary(lmSimL)$sigma</code>), and</li>
<li>the <span class="math inline">\(R^2\)</span> to be 0.7566342 (using <code>summary(lmSimL)$r.squared</code>).</li>
</ul>
<p>All the parameters were suitably estimated, not surprising since the amount of error was moderate, reflecting that the <code>xs</code> have a good explanatory power over the <code>ys</code>.</p>
<p>Using the code above, experiment with changing the standard deviation of the error, and see what happens to the estimated <span class="math inline">\(R^2\)</span>, to the parameter estimates, to the estimated error, and to how close the estimated regression model is to the true model.</p>
<p>This is the amazing advantage of a simulation, which we do not have in real data: we know what reality is, and a true model exists!. This will give you a good feeling for what a regression model is and what is does, and what it can’t do. An example of what it can’t give you is reliable estimates when the error is large compared to the systematic part of the model, as illustrated next</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="aula6.html#cb43-1" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">97</span></span>
<span id="cb43-2"><a href="aula6.html#cb43-2" tabindex="-1"></a><span class="co">#simular comprimentos</span></span>
<span id="cb43-3"><a href="aula6.html#cb43-3" tabindex="-1"></a>comp.sim <span class="ot">&lt;-</span> <span class="fu">runif</span>(n,<span class="dv">5</span>,<span class="dv">20</span>)</span>
<span id="cb43-4"><a href="aula6.html#cb43-4" tabindex="-1"></a>a<span class="ot">&lt;-</span><span class="dv">12</span></span>
<span id="cb43-5"><a href="aula6.html#cb43-5" tabindex="-1"></a>b<span class="ot">&lt;-</span><span class="fl">1.2</span></span>
<span id="cb43-6"><a href="aula6.html#cb43-6" tabindex="-1"></a><span class="co">#simular pesos</span></span>
<span id="cb43-7"><a href="aula6.html#cb43-7" tabindex="-1"></a>peso.sim<span class="ot">&lt;-</span>a<span class="sc">+</span>b<span class="sc">*</span>comp.sim<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd=</span><span class="dv">2</span>)</span>
<span id="cb43-8"><a href="aula6.html#cb43-8" tabindex="-1"></a>data.sim<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">csim=</span>comp.sim,<span class="at">psim=</span>peso.sim)</span>
<span id="cb43-9"><a href="aula6.html#cb43-9" tabindex="-1"></a><span class="fu">plot</span>(psim<span class="sc">~</span>csim,<span class="at">data=</span>data.sim)</span>
<span id="cb43-10"><a href="aula6.html#cb43-10" tabindex="-1"></a>mod.sim<span class="ot">&lt;-</span><span class="fu">lm</span>(psim<span class="sc">~</span>csim,<span class="at">data=</span>data.sim)</span>
<span id="cb43-11"><a href="aula6.html#cb43-11" tabindex="-1"></a><span class="fu">abline</span>(mod.sim,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb43-12"><a href="aula6.html#cb43-12" tabindex="-1"></a><span class="fu">summary</span>(mod.sim)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = psim ~ csim, data = data.sim)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3460 -1.1652  0.1329  1.5072  3.0036 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 11.70390    0.56783   20.61   &lt;2e-16 ***
## csim         1.20912    0.04325   27.96   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.822 on 95 degrees of freedom
## Multiple R-squared:  0.8916, Adjusted R-squared:  0.8905 
## F-statistic: 781.6 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="aula6.html#cb45-1" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb45-2"><a href="aula6.html#cb45-2" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Estimated line&quot;</span>,<span class="st">&quot;True model&quot;</span>),<span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;red&quot;</span>,<span class="st">&quot;green&quot;</span>),<span class="at">lty=</span><span class="dv">1</span>,<span class="at">inset=</span><span class="fl">0.05</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.26-1.png" width="672" /></p>
<div id="what-is-the-effect-of-increasing-the-error-a-simulation-experiment" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> What is the effect of increasing the error: a simulation experiment<a href="aula6.html#what-is-the-effect-of-increasing-the-error-a-simulation-experiment" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, let’s consider there’s more and less variance. We also add to each plot the real line (that with the true parameter values) and the one with the estimated parameter values.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="aula6.html#cb46-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb46-2"><a href="aula6.html#cb46-2" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb46-3"><a href="aula6.html#cb46-3" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span>
<span id="cb46-4"><a href="aula6.html#cb46-4" tabindex="-1"></a>mod1<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb46-5"><a href="aula6.html#cb46-5" tabindex="-1"></a><span class="fu">abline</span>(mod1,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb46-6"><a href="aula6.html#cb46-6" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb46-7"><a href="aula6.html#cb46-7" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">2</span>)</span>
<span id="cb46-8"><a href="aula6.html#cb46-8" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span>
<span id="cb46-9"><a href="aula6.html#cb46-9" tabindex="-1"></a>mod2<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb46-10"><a href="aula6.html#cb46-10" tabindex="-1"></a><span class="fu">abline</span>(mod2,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb46-11"><a href="aula6.html#cb46-11" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb46-12"><a href="aula6.html#cb46-12" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">4</span>)</span>
<span id="cb46-13"><a href="aula6.html#cb46-13" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span>
<span id="cb46-14"><a href="aula6.html#cb46-14" tabindex="-1"></a>mod4<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb46-15"><a href="aula6.html#cb46-15" tabindex="-1"></a><span class="fu">abline</span>(mod4,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb46-16"><a href="aula6.html#cb46-16" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb46-17"><a href="aula6.html#cb46-17" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb46-18"><a href="aula6.html#cb46-18" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span>
<span id="cb46-19"><a href="aula6.html#cb46-19" tabindex="-1"></a>mod10<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb46-20"><a href="aula6.html#cb46-20" tabindex="-1"></a><span class="fu">abline</span>(mod10,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb46-21"><a href="aula6.html#cb46-21" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb46-22"><a href="aula6.html#cb46-22" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">20</span>)</span>
<span id="cb46-23"><a href="aula6.html#cb46-23" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span>
<span id="cb46-24"><a href="aula6.html#cb46-24" tabindex="-1"></a>mod20<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb46-25"><a href="aula6.html#cb46-25" tabindex="-1"></a><span class="fu">abline</span>(mod20,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb46-26"><a href="aula6.html#cb46-26" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb46-27"><a href="aula6.html#cb46-27" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">100</span>)</span>
<span id="cb46-28"><a href="aula6.html#cb46-28" tabindex="-1"></a><span class="fu">plot</span>(xs,ys)</span>
<span id="cb46-29"><a href="aula6.html#cb46-29" tabindex="-1"></a>mod100<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb46-30"><a href="aula6.html#cb46-30" tabindex="-1"></a><span class="fu">abline</span>(mod100,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb46-31"><a href="aula6.html#cb46-31" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.27-1.png" width="672" /></p>
<p>Not surprisingly, as the variance increases, we get data that more and more looks like it is not coming from a real linear process.</p>
<p>You can also look at the model summaries, and there you can see that, in fact, the models become essentially useless as the variance increases! You can see that both from the correlation, but also by the predictions generated from the model (comparing to the truth), and also the significance of the coefficients associated with the regression parameters.</p>
<p>Make no mistake, the reality is always the same, in terms of the fixed part of the model, it is just the variance that we observe reality with that increases. This could happen either because the model is not adequate (e.g. there are other variables than just length that explain the weight) but also because the measurement error in the weights might be larger (e.g. think about measuring the weight of whales, instead that of lizards, say).</p>
<p>Also, do not get confused, the different green lines might look different, but they are always exactly the same line, the same true model is constant across all plots! You can check that by forcing the y axis to span the same limits.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="aula6.html#cb47-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb47-2"><a href="aula6.html#cb47-2" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb47-3"><a href="aula6.html#cb47-3" tabindex="-1"></a><span class="fu">plot</span>(xs,ys,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">400</span>,<span class="dv">400</span>))</span>
<span id="cb47-4"><a href="aula6.html#cb47-4" tabindex="-1"></a>mod1<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb47-5"><a href="aula6.html#cb47-5" tabindex="-1"></a><span class="fu">abline</span>(mod1,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb47-6"><a href="aula6.html#cb47-6" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb47-7"><a href="aula6.html#cb47-7" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">2</span>)</span>
<span id="cb47-8"><a href="aula6.html#cb47-8" tabindex="-1"></a><span class="fu">plot</span>(xs,ys,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">400</span>,<span class="dv">400</span>))</span>
<span id="cb47-9"><a href="aula6.html#cb47-9" tabindex="-1"></a>mod2<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb47-10"><a href="aula6.html#cb47-10" tabindex="-1"></a><span class="fu">abline</span>(mod2,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb47-11"><a href="aula6.html#cb47-11" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb47-12"><a href="aula6.html#cb47-12" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">4</span>)</span>
<span id="cb47-13"><a href="aula6.html#cb47-13" tabindex="-1"></a><span class="fu">plot</span>(xs,ys,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">400</span>,<span class="dv">400</span>))</span>
<span id="cb47-14"><a href="aula6.html#cb47-14" tabindex="-1"></a>mod4<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb47-15"><a href="aula6.html#cb47-15" tabindex="-1"></a><span class="fu">abline</span>(mod4,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb47-16"><a href="aula6.html#cb47-16" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb47-17"><a href="aula6.html#cb47-17" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb47-18"><a href="aula6.html#cb47-18" tabindex="-1"></a><span class="fu">plot</span>(xs,ys,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">400</span>,<span class="dv">400</span>))</span>
<span id="cb47-19"><a href="aula6.html#cb47-19" tabindex="-1"></a>mod10<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb47-20"><a href="aula6.html#cb47-20" tabindex="-1"></a><span class="fu">abline</span>(mod10,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb47-21"><a href="aula6.html#cb47-21" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb47-22"><a href="aula6.html#cb47-22" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">20</span>)</span>
<span id="cb47-23"><a href="aula6.html#cb47-23" tabindex="-1"></a><span class="fu">plot</span>(xs,ys,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">400</span>,<span class="dv">400</span>))</span>
<span id="cb47-24"><a href="aula6.html#cb47-24" tabindex="-1"></a>mod20<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb47-25"><a href="aula6.html#cb47-25" tabindex="-1"></a><span class="fu">abline</span>(mod20,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb47-26"><a href="aula6.html#cb47-26" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb47-27"><a href="aula6.html#cb47-27" tabindex="-1"></a>ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">100</span>)</span>
<span id="cb47-28"><a href="aula6.html#cb47-28" tabindex="-1"></a><span class="fu">plot</span>(xs,ys,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">400</span>,<span class="dv">400</span>))</span>
<span id="cb47-29"><a href="aula6.html#cb47-29" tabindex="-1"></a>mod100<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb47-30"><a href="aula6.html#cb47-30" tabindex="-1"></a><span class="fu">abline</span>(mod100,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb47-31"><a href="aula6.html#cb47-31" tabindex="-1"></a><span class="fu">abline</span>(a,b,<span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.28-1.png" width="672" /></p>
<p>but since then you loose all the ability to look at the actual data in some of the plots, that representation is not really that useful!</p>
<p>Below we tabulate the summary statistics for of each model with increasing variance, focusing on the estimated values for the parameters, their corresponding variances and the <span class="math inline">\(R^2\)</span>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="aula6.html#cb48-1" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb48-2"><a href="aula6.html#cb48-2" tabindex="-1"></a>model.stats<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">error=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">100</span>),<span class="at">intercept=</span><span class="cn">NA</span>,<span class="at">ise=</span><span class="cn">NA</span>,<span class="at">slope=</span><span class="cn">NA</span>,<span class="at">sse=</span><span class="cn">NA</span>,<span class="at">sde=</span><span class="cn">NA</span>,<span class="at">R2=</span><span class="cn">NA</span>)</span>
<span id="cb48-3"><a href="aula6.html#cb48-3" tabindex="-1"></a>model.stats[<span class="dv">1</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>]<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(mod1))[<span class="dv">1</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">coef</span>(<span class="fu">summary</span>(mod1))[<span class="dv">2</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">summary</span>(mod1)<span class="sc">$</span>sigma,<span class="fu">summary</span>(mod1)<span class="sc">$</span>r.squared)</span>
<span id="cb48-4"><a href="aula6.html#cb48-4" tabindex="-1"></a>model.stats[<span class="dv">2</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>]<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(mod2))[<span class="dv">1</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">coef</span>(<span class="fu">summary</span>(mod2))[<span class="dv">2</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">summary</span>(mod2)<span class="sc">$</span>sigma,<span class="fu">summary</span>(mod2)<span class="sc">$</span>r.squared)</span>
<span id="cb48-5"><a href="aula6.html#cb48-5" tabindex="-1"></a>model.stats[<span class="dv">3</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>]<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(mod4))[<span class="dv">1</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">coef</span>(<span class="fu">summary</span>(mod4))[<span class="dv">2</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">summary</span>(mod1)<span class="sc">$</span>sigma,<span class="fu">summary</span>(mod4)<span class="sc">$</span>r.squared)</span>
<span id="cb48-6"><a href="aula6.html#cb48-6" tabindex="-1"></a>model.stats[<span class="dv">4</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>]<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(mod10))[<span class="dv">1</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">coef</span>(<span class="fu">summary</span>(mod10))[<span class="dv">2</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">summary</span>(mod1)<span class="sc">$</span>sigma,<span class="fu">summary</span>(mod10)<span class="sc">$</span>r.squared)</span>
<span id="cb48-7"><a href="aula6.html#cb48-7" tabindex="-1"></a>model.stats[<span class="dv">5</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>]<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(mod20))[<span class="dv">1</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">coef</span>(<span class="fu">summary</span>(mod20))[<span class="dv">2</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">summary</span>(mod1)<span class="sc">$</span>sigma,<span class="fu">summary</span>(mod20)<span class="sc">$</span>r.squared)</span>
<span id="cb48-8"><a href="aula6.html#cb48-8" tabindex="-1"></a>model.stats[<span class="dv">6</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>]<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(mod100))[<span class="dv">1</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">coef</span>(<span class="fu">summary</span>(mod100))[<span class="dv">2</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="fu">summary</span>(mod1)<span class="sc">$</span>sigma,<span class="fu">summary</span>(mod100)<span class="sc">$</span>r.squared)</span>
<span id="cb48-9"><a href="aula6.html#cb48-9" tabindex="-1"></a><span class="fu">kable</span>(model.stats,<span class="at">digits=</span><span class="dv">2</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">error</th>
<th align="right">intercept</th>
<th align="right">ise</th>
<th align="right">slope</th>
<th align="right">sse</th>
<th align="right">sde</th>
<th align="right">R2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">12.25</td>
<td align="right">0.34</td>
<td align="right">1.19</td>
<td align="right">0.03</td>
<td align="right">1.08</td>
<td align="right">0.96</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">11.23</td>
<td align="right">0.67</td>
<td align="right">1.26</td>
<td align="right">0.05</td>
<td align="right">2.13</td>
<td align="right">0.87</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">12.94</td>
<td align="right">1.26</td>
<td align="right">1.12</td>
<td align="right">0.10</td>
<td align="right">1.08</td>
<td align="right">0.59</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">12.19</td>
<td align="right">3.01</td>
<td align="right">1.21</td>
<td align="right">0.23</td>
<td align="right">1.08</td>
<td align="right">0.23</td>
</tr>
<tr class="odd">
<td align="right">20</td>
<td align="right">9.24</td>
<td align="right">6.40</td>
<td align="right">1.67</td>
<td align="right">0.49</td>
<td align="right">1.08</td>
<td align="right">0.11</td>
</tr>
<tr class="even">
<td align="right">100</td>
<td align="right">41.65</td>
<td align="right">30.10</td>
<td align="right">-0.55</td>
<td align="right">2.29</td>
<td align="right">1.08</td>
<td align="right">0.00</td>
</tr>
</tbody>
</table>
<p>As an example, we can plot the <span class="math inline">\(R^2\)</span> as a function of the variance</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="aula6.html#cb49-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">100</span>),<span class="fu">c</span>(<span class="fu">summary</span>(mod1)<span class="sc">$</span>r.squared,<span class="fu">summary</span>(mod2)<span class="sc">$</span>r.squared,<span class="fu">summary</span>(mod4)<span class="sc">$</span>r.squared,<span class="fu">summary</span>(mod10)<span class="sc">$</span>r.squared,<span class="fu">summary</span>(mod20)<span class="sc">$</span>r.squared,<span class="fu">summary</span>(mod100)<span class="sc">$</span>r.squared),<span class="at">xlab=</span><span class="st">&quot;R^2&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Standard deviation of the error&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.30-1.png" width="672" /></p>
<p>That is quite interesting actually. There seems to be a nonlinear relationship, but we only have a sample size of six different standard deviations, i.e., variances, as variance is standard deviation squared, so it is hard to tell. But we can bring in the power of a <code>for</code> loop to do this for us for many values of the errors. We can then plot the results:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="aula6.html#cb50-1" tabindex="-1"></a>sds<span class="ot">=</span><span class="fu">seq</span>(<span class="fl">0.5</span>,<span class="dv">100</span>,<span class="at">by=</span><span class="fl">0.5</span>)</span>
<span id="cb50-2"><a href="aula6.html#cb50-2" tabindex="-1"></a>nsds<span class="ot">=</span><span class="fu">length</span>(sds)</span>
<span id="cb50-3"><a href="aula6.html#cb50-3" tabindex="-1"></a><span class="co">#an object to hold the correlations</span></span>
<span id="cb50-4"><a href="aula6.html#cb50-4" tabindex="-1"></a>Rsqs<span class="ot">=</span><span class="fu">numeric</span>(nsds)</span>
<span id="cb50-5"><a href="aula6.html#cb50-5" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsds){</span>
<span id="cb50-6"><a href="aula6.html#cb50-6" tabindex="-1"></a>  <span class="co">#create data</span></span>
<span id="cb50-7"><a href="aula6.html#cb50-7" tabindex="-1"></a>  ys<span class="ot">=</span>a<span class="sc">+</span>b<span class="sc">*</span>xs<span class="sc">+</span><span class="fu">rnorm</span>(n,<span class="dv">0</span>,sds[i])</span>
<span id="cb50-8"><a href="aula6.html#cb50-8" tabindex="-1"></a>  <span class="co">#estimate model</span></span>
<span id="cb50-9"><a href="aula6.html#cb50-9" tabindex="-1"></a>  modi<span class="ot">=</span><span class="fu">lm</span>(ys<span class="sc">~</span>xs)</span>
<span id="cb50-10"><a href="aula6.html#cb50-10" tabindex="-1"></a>  <span class="co">#get R-squared</span></span>
<span id="cb50-11"><a href="aula6.html#cb50-11" tabindex="-1"></a>  Rsqs[i]<span class="ot">=</span><span class="fu">summary</span>(modi)<span class="sc">$</span>r.squared</span>
<span id="cb50-12"><a href="aula6.html#cb50-12" tabindex="-1"></a>}</span>
<span id="cb50-13"><a href="aula6.html#cb50-13" tabindex="-1"></a><span class="co">#and at the end... plot results</span></span>
<span id="cb50-14"><a href="aula6.html#cb50-14" tabindex="-1"></a><span class="fu">plot</span>(sds,Rsqs)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.31-1.png" width="672" /></p>
<p>How cool is that! There seems to be evidence of a clear pattern, as anticipated. There is noise in the relation, and that comes because at each iteration there is randomness in the simulated data. Can you think of a way to reduce the noise in the pattern shown? If so, do it yourself!</p>
<p>This means we can model the <span class="math inline">\(R^2\)</span> as a function of the original variance! But we would not be able to model it using a linear model. While you are supposed to know about this yet, generalized linear models, which can be implemented with the help of function <code>gam</code> in package <code>mgcv</code> can come to our help. Later on we will earn more about GAM’s, but for now you can take a look at Noam Ross’s outstanding online free course on them (<a href="https://noamross.github.io/gams-in-r-course/" class="uri">https://noamross.github.io/gams-in-r-course/</a>) if you can’t wait for it.</p>
<p>Here I will just use it as is, you might see the syntax is quite similar to that of the <code>lm</code> function, we simply add syntax to reflect that we have non-linear, smooth terms of covariates (say e.g. <code>s(x)</code>).</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="aula6.html#cb51-1" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span></code></pre></div>
<pre><code>## Loading required package: nlme</code></pre>
<pre><code>## This is mgcv 1.8-42. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;.</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="aula6.html#cb54-1" tabindex="-1"></a>gam1<span class="ot">=</span><span class="fu">gam</span>(Rsqs<span class="sc">~</span><span class="fu">s</span>(sds),<span class="at">link=</span>log)</span>
<span id="cb54-2"><a href="aula6.html#cb54-2" tabindex="-1"></a><span class="co">#make predictions to plot the estimated GAM model</span></span>
<span id="cb54-3"><a href="aula6.html#cb54-3" tabindex="-1"></a>predRsqs<span class="ot">=</span><span class="fu">predict.gam</span>(gam1,<span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">sds=</span>sds),<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb54-4"><a href="aula6.html#cb54-4" tabindex="-1"></a><span class="fu">plot</span>(sds,Rsqs)</span>
<span id="cb54-5"><a href="aula6.html#cb54-5" tabindex="-1"></a><span class="fu">lines</span>(sds,predRsqs,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.32-1.png" width="672" /></p>
<p>While we have not yet talked about it, intuitively it seems like the model over-fitted to the data. In other words, the model is too much flexible. Therefore, I constrain the GAM to be not as wiggly (while it might sound like a funny madeup word, the “wiggliness” of a GAM is a technical term used even in publications) by changing the argument <code>k</code> which defines the degrees of freedom in the smooth term.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="aula6.html#cb55-1" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb55-2"><a href="aula6.html#cb55-2" tabindex="-1"></a>gam1<span class="ot">=</span><span class="fu">gam</span>(Rsqs<span class="sc">~</span><span class="fu">s</span>(sds,<span class="at">k=</span><span class="dv">3</span>),<span class="at">link=</span>log)</span>
<span id="cb55-3"><a href="aula6.html#cb55-3" tabindex="-1"></a><span class="co">#make predictions to plot the estimated GAM model</span></span>
<span id="cb55-4"><a href="aula6.html#cb55-4" tabindex="-1"></a>predRsqs<span class="ot">=</span><span class="fu">predict.gam</span>(gam1,<span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">sds=</span>sds),<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb55-5"><a href="aula6.html#cb55-5" tabindex="-1"></a><span class="fu">plot</span>(sds,Rsqs)</span>
<span id="cb55-6"><a href="aula6.html#cb55-6" tabindex="-1"></a><span class="fu">lines</span>(sds,predRsqs,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.33-1.png" width="672" /></p>
<p>That was too much constraining, so now we are under-fitting, the model in not flexible enough to fit the data. We increase the allowed level of wiggliness again</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="aula6.html#cb56-1" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb56-2"><a href="aula6.html#cb56-2" tabindex="-1"></a>gam1<span class="ot">=</span><span class="fu">gam</span>(Rsqs<span class="sc">~</span><span class="fu">s</span>(sds,<span class="at">k=</span><span class="dv">6</span>),<span class="at">link=</span>log)</span>
<span id="cb56-3"><a href="aula6.html#cb56-3" tabindex="-1"></a><span class="co">#make predictions to plot the estimated GAM model</span></span>
<span id="cb56-4"><a href="aula6.html#cb56-4" tabindex="-1"></a>predRsqs<span class="ot">=</span><span class="fu">predict.gam</span>(gam1,<span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">sds=</span>sds),<span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb56-5"><a href="aula6.html#cb56-5" tabindex="-1"></a><span class="fu">plot</span>(sds,Rsqs)</span>
<span id="cb56-6"><a href="aula6.html#cb56-6" tabindex="-1"></a><span class="fu">lines</span>(sds,predRsqs,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ECOMODbook_files/figure-html/a6.34-1.png" width="672" /></p>
<p>but that is already over-fitting… conclusion, the GAM might not be the right tool here :) Perhaps we could consider a model that embedds some understanding about the process between the two quantities, which is presumably possible to achieve by exploring analytically what said relation should be.</p>
<p>Being happy with the visual illustration of the relation and the preview of how the use of a more flexible apporach than a linear model might be useful to fit models to data, we will leave that implementation for readers which might find it an interesting but non-trivial exercise.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="handson.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="aula7.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ECOMODbook.pdf", "ECOMODbook.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
